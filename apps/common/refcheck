#!/usr/bin/env python3
"""
refcheck - Find broken file references and fragile path patterns

A fast reference validator for codebases. Catches broken source statements,
missing script references, old path patterns, and fragile paths that break
when run from different directories or after file moves.

Designed for:
  - Proactive error detection before running tests
  - Refactoring safety (find stale references after moving files)
  - Path fragility detection (warn about working-directory-dependent paths)
  - Fast feedback (runs in seconds vs minutes for full test suites)

Common workflows:
  refcheck                           # Validate all references + warn about fragile paths
  refcheck --no-warn                 # Only check for errors, skip warnings
  refcheck --strict                  # Treat warnings as errors (CI mode)
  refcheck management/               # Check specific directory
  refcheck --pattern "old/" --desc "Now new/"  # After refactoring
  refcheck --type sh --skip-docs     # Only shell scripts, skip docs
"""

import re
import sys
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass
from enum import Enum
import argparse


class CheckType(Enum):
    PATTERN = "old_path_pattern"
    SOURCE = "broken_source_command"
    SCRIPT = "broken_bash_command"
    FRAGILE_CWD = "fragile_cwd_path"
    FRAGILE_REFACTOR = "fragile_traversal_path"


@dataclass
class Issue:
    file: Path
    line_num: int
    check_type: CheckType
    message: str
    suggestion: Optional[str] = None


@dataclass
class Warning:
    file: Path
    line_num: int
    check_type: CheckType
    message: str
    suggestion: Optional[str] = None


class ReferenceChecker:
    """Validates file references across a codebase."""

    DEFAULT_EXCLUDES = {
        ".git",
        "node_modules",
        ".venv",
        "site",
        "__pycache__",
        ".cache",
    }

    DEFAULT_EXCLUDE_PATTERNS = [
        "*.pyc",
        ".claude/metrics/**",
        ".planning/**",
        "site/**",
    ]

    # Patterns excluded in normal mode but included with --test-mode
    TEST_FIXTURE_PATTERNS = [
        "tests/apps/test-refcheck.sh",
        "tests/apps/fixtures/refcheck-*/**",
        "docs/archive/**",
    ]

    DYNAMIC_PATH_PATTERNS = [
        r"^\$",
        r"^/tmp/",
        r"^/root/",
        r"^/home/",
        r"^/Users/",
        r"/nvm\.sh$",
        r"^/lib/lib\.sh",
    ]

    def __init__(
        self,
        root_dir: Path = None,
        search_path: Path = None,
        skip_docs: bool = False,
        file_type: str = None,
        warn_fragile: bool = True,
        strict: bool = False,
        test_mode: bool = False,
    ):
        self.root_dir = root_dir or Path.cwd()
        self.search_path = search_path or self.root_dir
        self.skip_docs = skip_docs
        self.file_type = file_type
        self.warn_fragile = warn_fragile
        self.strict = strict
        self.test_mode = test_mode
        self.issues: List[Issue] = []
        self.warnings: List[Warning] = []
        self.exclude_dirs = self.DEFAULT_EXCLUDES.copy()
        self.exclude_patterns = self.DEFAULT_EXCLUDE_PATTERNS.copy()

        # Exclude test fixtures unless in test mode
        if not test_mode:
            self.exclude_patterns.extend(self.TEST_FIXTURE_PATTERNS)

    def should_skip_file(self, file_path: Path) -> bool:
        """Determine if file should be skipped."""
        for part in file_path.parts:
            if part in self.exclude_dirs:
                return True

        for pattern in self.exclude_patterns:
            if file_path.match(pattern):
                return True

        if file_path.suffix in {".pyc", ".so", ".o", ".a", ".dylib"}:
            return True

        return False

    def is_dynamic_path(self, path: str) -> bool:
        """Check if path is dynamic/runtime-generated."""
        for pattern in self.DYNAMIC_PATH_PATTERNS:
            if re.search(pattern, path):
                return True
        return False

    def find_files(self, pattern: str = "**/*") -> List[Path]:
        """Find all files matching pattern, respecting exclusions."""
        files = []
        search_root = self.search_path

        for file_path in search_root.glob(pattern):
            if not file_path.is_file():
                continue

            try:
                rel_path = file_path.relative_to(self.root_dir)
            except ValueError:
                continue

            if self.should_skip_file(rel_path):
                continue

            if self.file_type and file_path.suffix != f".{self.file_type}":
                continue

            files.append(file_path)

        return files

    def check_pattern(self, pattern: str, description: str = None):
        """Check for old path pattern references."""
        description = description or f"Old pattern: {pattern}"

        for file_path in self.find_files():
            if self.skip_docs and file_path.suffix == ".md":
                continue

            # Skip verification scripts themselves
            if file_path.name in ("refcheck", "verify-references.py", "verify-file-references.sh"):
                continue

            try:
                rel_path = file_path.relative_to(self.root_dir)
                with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                    for line_num, line in enumerate(f, 1):
                        if pattern in line:
                            self.issues.append(
                                Issue(
                                    file=rel_path,
                                    line_num=line_num,
                                    check_type=CheckType.PATTERN,
                                    message=f"Found: {pattern}",
                                    suggestion=description,
                                )
                            )
            except (OSError, UnicodeDecodeError):
                continue

    def check_source_statements(self):
        """Check that source statements point to existing files."""
        source_pattern = re.compile(
            r'source\s+["\']([^"\']+)["\']|source\s+\$[^/]*(/[^\s]+)'
        )

        for file_path in self.find_files("**/*.sh"):
            try:
                rel_path = file_path.relative_to(self.root_dir)

                # Build symbol table for this file
                symbol_table = self.parse_variable_assignments(file_path)

                with open(file_path, "r", encoding="utf-8") as f:
                    for line_num, line in enumerate(f, 1):
                        if "source" not in line:
                            continue

                        match = source_pattern.search(line)
                        if not match:
                            continue

                        source_path = match.group(1) or match.group(2)
                        if not source_path:
                            continue

                        # Check if path is dynamic BEFORE trying to resolve variables
                        # (only check original path, not resolved paths)
                        if not '$' in source_path and self.is_dynamic_path(source_path):
                            continue

                        # Try to resolve variables in the path
                        original_path = source_path
                        if '$' in source_path:
                            try:
                                source_path = self.resolve_path(source_path, symbol_table, file_path)
                            except ValueError:
                                # Cannot resolve this path - skip gracefully
                                continue

                        if source_path.startswith("/"):
                            resolved = Path(source_path)
                        else:
                            resolved = self.root_dir / source_path

                        if not resolved.exists():
                            self.issues.append(
                                Issue(
                                    file=rel_path,
                                    line_num=line_num,
                                    check_type=CheckType.SOURCE,
                                    message=f"Missing: {original_path}" + (
                                        f" → {source_path}" if original_path != source_path else ""
                                    ),
                                    suggestion="Verify path exists or update reference",
                                )
                            )
            except (OSError, UnicodeDecodeError):
                continue

    def go_up_n_levels(self, file_path: Path, n: int) -> Path:
        """Go up N directory levels from file_path."""
        path = file_path.parent
        for _ in range(n - 1):
            path = path.parent
        return path

    def find_repo_root(self, file_path: Path) -> Path:
        """Find git repo root from file path."""
        current = file_path.parent
        while current != current.parent:  # Stop at filesystem root
            if (current / ".git").exists():
                return current
            current = current.parent
        # If no .git found, return current root_dir
        return self.root_dir

    def parse_variable_assignments(self, file_path: Path) -> Dict[str, str]:
        """
        Parse common shell variable assignment patterns.
        Returns dict of {var_name: computed_value}
        """
        symbol_table = {}

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
        except (OSError, UnicodeDecodeError):
            return symbol_table

        # Pattern 1: SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
        if re.search(r'SCRIPT_DIR="\$\(cd.*BASH_SOURCE', content):
            symbol_table['SCRIPT_DIR'] = str(file_path.parent)

        # Pattern 2: DOTFILES_DIR="$(cd "$SCRIPT_DIR/../.." && pwd)"
        # Extract the number of ../ levels
        match = re.search(r'DOTFILES_DIR="\$\(cd "\$SCRIPT_DIR/((?:\.\./?)+)" && pwd\)"', content)
        if match:
            relative_path = match.group(1)
            levels_up = relative_path.count('..')
            # We need to go up from the file's parent directory
            symbol_table['DOTFILES_DIR'] = str(self.go_up_n_levels(file_path, levels_up + 1))

        # Pattern 3: DOTFILES_DIR="${DOTFILES_DIR:-$HOME/dotfiles}"
        if re.search(r'DOTFILES_DIR="\$\{DOTFILES_DIR:-\$HOME/dotfiles\}"', content):
            # Use actual repo root if we can detect it
            symbol_table['DOTFILES_DIR'] = str(self.find_repo_root(file_path))

        return symbol_table

    def resolve_path(self, path_str: str, symbol_table: Dict[str, str], file_path: Path) -> str:
        """
        Resolve a path containing shell variables.

        Args:
            path_str: Path that may contain variables (e.g., "$SCRIPT_DIR/helpers.sh")
            symbol_table: Dictionary of variable names to their resolved values
            file_path: The file being checked (for context)

        Returns:
            Resolved path with variables substituted

        Raises:
            ValueError: If path contains unresolvable variables
        """
        resolved = path_str

        # Substitute known variables from symbol table
        for var_name, var_value in symbol_table.items():
            # Handle both $VAR and ${VAR} syntax
            resolved = resolved.replace(f"${var_name}", var_value)
            resolved = resolved.replace(f"${{{var_name}}}", var_value)

        # Check if there are still unresolved variables
        if '$' in resolved:
            # Can't resolve this path - raise exception
            raise ValueError(f"Cannot resolve variables in: {path_str}")

        return resolved

    def check_script_references(self):
        """Check that bash script references point to existing files."""
        script_pattern = re.compile(r'(?:bash|sh)\s+["\']?([^\s"\']+\.sh)["\']?')

        for file_path in self.find_files("**/*.sh"):
            if self.skip_docs and file_path.suffix == ".md":
                continue

            try:
                rel_path = file_path.relative_to(self.root_dir)
                with open(file_path, "r", encoding="utf-8") as f:
                    for line_num, line in enumerate(f, 1):
                        if "bash" not in line and "sh" not in line:
                            continue

                        for match in script_pattern.finditer(line):
                            script_path = match.group(1).rstrip('"\'')

                            if not script_path or self.is_dynamic_path(script_path):
                                continue

                            # Skip self-references in usage comments
                            if (
                                line.strip().startswith("#")
                                and script_path == file_path.name
                            ):
                                continue

                            if script_path.startswith("/"):
                                resolved = Path(script_path)
                            else:
                                resolved = self.root_dir / script_path

                            if not resolved.exists():
                                self.issues.append(
                                    Issue(
                                        file=rel_path,
                                        line_num=line_num,
                                        check_type=CheckType.SCRIPT,
                                        message=f"Missing: {script_path}",
                                        suggestion="Verify script exists or update reference",
                                    )
                                )
            except (OSError, UnicodeDecodeError):
                continue

    def check_relative_path_fragility(self):
        """Check if relative paths are fragile to working directory changes."""
        # Match: source "path" OR source 'path' OR source path (unquoted)
        source_pattern = re.compile(
            r'source\s+(?:["\']([^"\']+)["\']|([^\s]+))'
        )

        for file_path in self.find_files("**/*.sh"):
            try:
                rel_path = file_path.relative_to(self.root_dir)

                # Build symbol table for this file
                symbol_table = self.parse_variable_assignments(file_path)

                with open(file_path, "r", encoding="utf-8") as f:
                    for line_num, line in enumerate(f, 1):
                        if "source" not in line:
                            continue

                        match = source_pattern.search(line)
                        if not match:
                            continue

                        source_path = match.group(1) or match.group(2)
                        if not source_path:
                            continue

                        # Skip if it has variables (will be resolved) or is absolute or dynamic
                        if '$' in source_path or source_path.startswith("/") or self.is_dynamic_path(source_path):
                            continue

                        # This is a plain relative path - test from multiple directories
                        test_dirs = [
                            self.root_dir,              # Repo root
                            file_path.parent,           # Script's directory
                            file_path.parent.parent,    # One level up
                        ]

                        valid_from = []
                        for test_dir in test_dirs:
                            resolved = test_dir / source_path
                            if resolved.exists():
                                valid_from.append(test_dir)

                        # If it only works from some directories (not all), it's fragile
                        if len(valid_from) > 0 and len(valid_from) < len(test_dirs):
                            try:
                                valid_desc = ", ".join(str(d.relative_to(self.root_dir)) if d != self.root_dir else "repo root" for d in valid_from)
                            except ValueError:
                                valid_desc = ", ".join(str(d) for d in valid_from)

                            self.warnings.append(
                                Warning(
                                    file=rel_path,
                                    line_num=line_num,
                                    check_type=CheckType.FRAGILE_CWD,
                                    message=f"Relative path only valid from: {valid_desc}",
                                    suggestion="Use absolute path or root directory variable (e.g., $PROJECT_ROOT, $REPO_ROOT)",
                                )
                            )
            except (OSError, UnicodeDecodeError):
                continue

    def check_relative_traversal(self):
        """Detect relative directory traversal patterns fragile to file moves."""
        # Pattern: VARIABLE_DIR="$(cd "$OTHER_DIR/../../.." && pwd)"
        traversal_pattern = re.compile(
            r'([A-Z_]+_DIR)=.*\$\(cd.*\.\./.*pwd\)'
        )

        for file_path in self.find_files("**/*.sh"):
            try:
                rel_path = file_path.relative_to(self.root_dir)

                with open(file_path, "r", encoding="utf-8") as f:
                    for line_num, line in enumerate(f, 1):
                        match = traversal_pattern.search(line)
                        if not match:
                            continue

                        var_name = match.group(1)

                        self.warnings.append(
                            Warning(
                                file=rel_path,
                                line_num=line_num,
                                check_type=CheckType.FRAGILE_REFACTOR,
                                message=f"{var_name} uses relative directory traversal (../) - fragile to file moves",
                                suggestion="Consider dynamic root detection: git rev-parse --show-toplevel, or search for project marker (.git, etc.)",
                            )
                        )
            except (OSError, UnicodeDecodeError):
                continue

    def run_all_checks(self):
        """Run all validation checks."""
        self.check_pattern("management/tests/", "Update to tests/install/")
        self.check_source_statements()
        self.check_script_references()

        # Only run warning checks if enabled
        if self.warn_fragile:
            self.check_relative_path_fragility()
            self.check_relative_traversal()

    def print_results(self):
        """Print validation results."""
        try:
            search_info = f" in {self.search_path.relative_to(self.root_dir)}" if self.search_path != self.root_dir else ""

            # If no issues or warnings, success!
            if not self.issues and not self.warnings:
                print(f"\n✅ All file references valid{search_info}\n")
                return

            # Print summary header
            error_count = len(self.issues)
            warning_count = len(self.warnings)

            if error_count > 0 and warning_count > 0:
                print(f"\n❌ Found {error_count} error(s) and {warning_count} warning(s){search_info}\n")
            elif error_count > 0:
                print(f"\n❌ Found {error_count} error(s){search_info}\n")
            else:
                print(f"\n⚠️  Found {warning_count} warning(s){search_info}\n")

            # Print errors
            if self.issues:
                print("Errors:")
                print("─" * 60)

                by_type: Dict[CheckType, List[Issue]] = {}
                for issue in self.issues:
                    by_type.setdefault(issue.check_type, []).append(issue)

                for check_type, issues in sorted(by_type.items(), key=lambda x: x[0].value):
                    print(f"\n{check_type.value.replace('_', ' ').title()} ({len(issues)}):")
                    print("─" * 60)
                    for issue in issues:
                        print(f"  {issue.file}:{issue.line_num}")
                        print(f"    {issue.message}")
                        if issue.suggestion:
                            print(f"    → {issue.suggestion}")

            # Print warnings
            if self.warnings:
                if self.issues:
                    print()  # Extra space between errors and warnings

                print("Warnings:")
                print("─" * 60)

                by_type: Dict[CheckType, List[Warning]] = {}
                for warning in self.warnings:
                    by_type.setdefault(warning.check_type, []).append(warning)

                for check_type, warnings in sorted(by_type.items(), key=lambda x: x[0].value):
                    print(f"\n{check_type.value.replace('_', ' ').title()} ({len(warnings)}):")
                    print("─" * 60)
                    for warning in warnings:
                        print(f"  {warning.file}:{warning.line_num}")
                        print(f"    {warning.message}")
                        if warning.suggestion:
                            print(f"    → {warning.suggestion}")

            print()
        except BrokenPipeError:
            sys.stderr.close()
            pass


def main():
    parser = argparse.ArgumentParser(
        prog="refcheck",
        description="Find broken file references and old path patterns",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Validate all references + warn about fragile paths
  %(prog)s
  %(prog)s --skip-docs              # Skip markdown files

  # Check specific directory
  %(prog)s management/
  %(prog)s apps/ --type sh          # Only shell scripts in apps/

  # Control warnings
  %(prog)s --no-warn                # Only check errors, skip fragile path warnings
  %(prog)s --strict                 # Treat warnings as errors (CI mode)

  # Find old patterns after refactoring
  %(prog)s --pattern "old/path/"
  %(prog)s --pattern "FooClass" --desc "Renamed to BarClass"

What it checks:
  Errors (always checked, exit 1):
    - Broken source commands (source statements pointing to non-existent files)
    - Broken bash commands (bash/sh invocations pointing to non-existent scripts)
    - Old path patterns (after moving/renaming directories)

  Warnings (checked by default, exit 0 unless --strict):
    - Fragile CWD paths: Relative paths that only work from specific directories
    - Fragile traversal paths: Directory variables using ../ traversal (fragile to file moves)

Exit codes:
  0 - No errors (warnings OK unless --strict)
  1 - Found errors, or warnings in --strict mode
        """,
    )
    parser.add_argument(
        "path",
        nargs="?",
        type=Path,
        help="Directory to check (default: current directory)",
    )
    parser.add_argument(
        "--pattern",
        metavar="PATTERN",
        help="Check for specific old path pattern (e.g., 'old/path/')",
    )
    parser.add_argument(
        "--desc",
        metavar="DESC",
        help="Description for pattern check",
    )
    parser.add_argument(
        "--type",
        "-t",
        metavar="TYPE",
        help="Filter by file type (e.g., 'sh', 'py')",
    )
    parser.add_argument(
        "--skip-docs",
        action="store_true",
        help="Skip documentation (.md) files",
    )
    parser.add_argument(
        "--strict",
        action="store_true",
        help="Treat warnings as errors (exit 1 if warnings found)",
    )
    parser.add_argument(
        "--no-warn",
        action="store_true",
        help="Disable fragile path warnings (only check for errors)",
    )
    parser.add_argument(
        "--test-mode",
        action="store_true",
        help="Include test fixtures (normally excluded)",
    )
    args = parser.parse_args()

    root_dir = Path.cwd()
    search_path = args.path.resolve() if args.path else root_dir

    # Ensure search_path is within or is root_dir
    try:
        search_path.relative_to(root_dir)
    except ValueError:
        # search_path is outside root_dir, use it as new root
        root_dir = search_path

    checker = ReferenceChecker(
        root_dir=root_dir,
        search_path=search_path,
        skip_docs=args.skip_docs,
        file_type=args.type,
        warn_fragile=not args.no_warn,
        strict=args.strict,
        test_mode=args.test_mode,
    )

    if args.pattern:
        checker.check_pattern(args.pattern, args.desc)
    else:
        checker.run_all_checks()

    checker.print_results()

    # Exit code logic:
    # - Always exit 1 if there are errors
    # - Exit 1 if strict mode and there are warnings
    # - Otherwise exit 0
    if checker.issues:
        sys.exit(1)
    elif checker.strict and checker.warnings:
        sys.exit(1)
    else:
        sys.exit(0)


if __name__ == "__main__":
    main()
